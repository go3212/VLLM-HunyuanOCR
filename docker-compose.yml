services:
  hunyuan-ocr:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: hunyuan-ocr
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # No exposed ports - traffic goes through proxy
    volumes:
      - huggingface-cache:/root/.cache/huggingface
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_HOME=/root/.cache/huggingface
      # Uncomment and set your token if needed for gated models
      # - HF_TOKEN=your_huggingface_token_here
    command: >
      vllm serve tencent/HunyuanOCR
        --no-enable-prefix-caching
        --mm-processor-cache-gb 0
        --enforce-eager
        --gpu-memory-utilization 0.4
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 120
      start_period: 300s
    # Don't auto-restart - proxy manages lifecycle
    restart: "no"

  # Smart proxy - handles requests and manages OCR server lifecycle
  # - Auto-starts OCR server when request comes in
  # - Waits for server to be healthy before forwarding
  # - Shuts down OCR server after idle timeout to free VRAM
  proxy:
    build:
      context: ./watchdog
      dockerfile: Dockerfile
    container_name: hunyuan-ocr-proxy
    ports:
      # This is now the main entry point
      - "8000:8000"
    environment:
      # Backend server (internal Docker network)
      - VLLM_URL=http://hunyuan-ocr:8000
      # Container to manage
      - CONTAINER_NAME=hunyuan-ocr
      # Idle timeout in seconds (default: 300 = 5 minutes)
      - IDLE_TIMEOUT=${IDLE_TIMEOUT:-300}
      # How often to check idle status (default: 30s)
      - CHECK_INTERVAL=${CHECK_INTERVAL:-30}
      # Max time to wait for server startup (default: 600 = 10 min)
      - STARTUP_TIMEOUT=${STARTUP_TIMEOUT:-600}
    volumes:
      # Mount docker socket to control the OCR container
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - hunyuan-ocr
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/proxy/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Legacy watchdog service (deprecated - use proxy instead)
  # Keeping for backwards compatibility, but proxy is preferred
  watchdog:
    build:
      context: ./watchdog
      dockerfile: Dockerfile
    container_name: hunyuan-ocr-watchdog
    profiles:
      - legacy
    environment:
      - VLLM_URL=http://hunyuan-ocr:8000
      - IDLE_TIMEOUT=${IDLE_TIMEOUT:-300}
      - CHECK_INTERVAL=${CHECK_INTERVAL:-30}
      - SHUTDOWN_COMMAND=docker stop hunyuan-ocr
    command: ["python", "-u", "idle_shutdown.py"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      hunyuan-ocr:
        condition: service_healthy
    restart: unless-stopped

  # Web frontend for testing OCR
  # Usage: docker compose --profile frontend up -d
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: hunyuan-ocr-frontend
    profiles:
      - frontend
    ports:
      - "8520:8520"
    environment:
      # Point to proxy instead of direct OCR server
      - OCR_SERVER_URL=http://hunyuan-ocr-proxy:8000
    depends_on:
      - proxy
    restart: unless-stopped

volumes:
  huggingface-cache:
